{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "u-NI5Ipg-yQD"
      ],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "D3I5juE8WHDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5904ca94-40d1-4b98-ecca-decebedea119"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies:"
      ],
      "metadata": {
        "id": "u-NI5Ipg-yQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision numpy torchinfo"
      ],
      "metadata": {
        "id": "77EtTYuF-P59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a9d0458-1ec1-46a9-ba5c-15096acd53ff"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: torchinfo in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as utils\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "from torchvision.transforms import v2\n",
        "import torchinfo\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import shutil"
      ],
      "metadata": {
        "id": "EY_Y-oZ7-sy1"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Initialization:"
      ],
      "metadata": {
        "id": "njQXG-v_z-Iq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Light U-Net:"
      ],
      "metadata": {
        "id": "OJdM6qO1qZnZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatureConvs(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, padding, dropout=0.0):\n",
        "    super().__init__()\n",
        "\n",
        "    self.feature_convs = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size, padding=padding, bias=False),\n",
        "        nn.BatchNorm2d(num_features=in_channels),\n",
        "        nn.ReLU(),\n",
        "\n",
        "        nn.Dropout(p=dropout),\n",
        "\n",
        "        nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, padding=padding, bias=False),\n",
        "        nn.BatchNorm2d(num_features=out_channels),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x): return self.feature_convs(x)\n",
        "\n",
        "\n",
        "class MLPBlock(nn.Module):\n",
        "  def __init__(self, in_dim, out_dim):\n",
        "    super().__init__()\n",
        "\n",
        "    self.mlp_block = nn.Sequential(\n",
        "        nn.Linear(in_features=in_dim, out_features=out_dim, bias=False),\n",
        "        nn.LayerNorm(normalized_shape=out_dim),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x): return self.mlp_block(x)\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, layer, kwargs):\n",
        "    super().__init__()\n",
        "    self.layer = layer\n",
        "\n",
        "    self.in_channels = kwargs.get('in_channels')[layer]\n",
        "    self.out_channels = kwargs.get('out_channels')[layer]\n",
        "    self.kernel_size = kwargs.get('kernel_size')\n",
        "    self.padding = kwargs.get('padding')\n",
        "    self.dropout = kwargs.get('dropout')\n",
        "\n",
        "    self.pool_stride = kwargs.get('pool_stride')\n",
        "\n",
        "    self.feature_convs = FeatureConvs(self.in_channels, self.out_channels, self.kernel_size, self.padding, self.dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    if self.layer != 0:\n",
        "      x = nn.functional.max_pool2d(x, kernel_size=self.pool_stride)\n",
        "\n",
        "    return self.feature_convs(x)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, layer, kwargs):\n",
        "    super().__init__()\n",
        "    self.layer = layer\n",
        "    self.layers = kwargs.get('layers')\n",
        "\n",
        "    self.in_channels = kwargs.get('out_channels')[layer]\n",
        "    self.out_channels = kwargs.get('in_channels')[layer]\n",
        "    self.kernel_size = kwargs.get('kernel_size')\n",
        "    self.padding = kwargs.get('padding')\n",
        "\n",
        "    self.pool_stride = kwargs.get('pool_stride')\n",
        "    self.pointwise = nn.Conv2d(in_channels=self.in_channels, out_channels=self.in_channels, kernel_size=1)\n",
        "\n",
        "    self.feature_convs = FeatureConvs(self.in_channels, self.out_channels, self.kernel_size, self.padding)\n",
        "\n",
        "  def forward(self, x, _x=None):\n",
        "    x = self.pointwise(nn.functional.interpolate(x, scale_factor=self.pool_stride))\n",
        "    x += _x\n",
        "\n",
        "    return self.feature_convs(x)\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "  def __init__(self, kwargs):\n",
        "    super().__init__()\n",
        "\n",
        "    self.dim_list = kwargs.get('mlp_dims')\n",
        "\n",
        "    self.mlp = nn.ModuleList([MLPBlock(i, o) for i, o in zip(self.dim_list[:-1], self.dim_list[1:])])\n",
        "\n",
        "    self.process_conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=kwargs.get('out_channels')[-1], out_channels=kwargs.get('in_channels')[-1], kernel_size=kwargs.get('kernel_size'), padding=kwargs.get('padding'), bias=False),\n",
        "        nn.BatchNorm2d(num_features=kwargs.get('in_channels')[-1]),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.permute(0, 2, 3, 1)\n",
        "\n",
        "    for i in self.mlp:\n",
        "      x = i(x)\n",
        "\n",
        "    x = x.permute(0, 3, 1, 2)\n",
        "    return self.process_conv(x)"
      ],
      "metadata": {
        "id": "AlTWbcvmqcGf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Light_UNet(nn.Module):\n",
        "  def __init__(self, **kwargs):\n",
        "    super().__init__()\n",
        "\n",
        "    self.enc_1 = Encoder(0, kwargs)\n",
        "    self.enc_2 = Encoder(1, kwargs)\n",
        "    self.enc_3 = Encoder(2, kwargs)\n",
        "    self.enc_4 = Encoder(3, kwargs)\n",
        "\n",
        "    self.dec_3 = Decoder(2, kwargs)\n",
        "    self.dec_2 = Decoder(1, kwargs)\n",
        "    self.dec_1 = Decoder(0, kwargs)\n",
        "\n",
        "    self.bottleneck = Bottleneck(kwargs)\n",
        "\n",
        "    self.first_conv = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=kwargs.get('feature_labels')[0], out_channels=kwargs.get('in_channels')[0], kernel_size=kwargs.get('kernel_size'), padding=kwargs.get('padding'), bias=False),\n",
        "        nn.BatchNorm2d(num_features=kwargs.get('in_channels')[0]),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.last_conv = nn.Conv2d(in_channels=kwargs.get('out_channels')[0], out_channels=kwargs.get('feature_labels')[-1], kernel_size=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_1 = self.enc_1(self.first_conv(x))\n",
        "    x_2 = self.enc_2(x_1)\n",
        "    x_3 = self.enc_3(x_2)\n",
        "    x_4 = self.bottleneck(self.enc_4(x_3))\n",
        "\n",
        "    x_3 = self.dec_3(x_4, x_3)\n",
        "    x_2 = self.dec_2(x_3, x_2)\n",
        "    x_1 = self.dec_1(x_2, x_1)\n",
        "\n",
        "    return self.last_conv(x_1)\n",
        "\n",
        "  def init_weights(self):\n",
        "    for m in self.modules():\n",
        "      if isinstance(m, nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, a=0, mode='fan_in', nonlinearity='relu')"
      ],
      "metadata": {
        "id": "QDyZlfUcDfLL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_config = {\n",
        "    'layers': 4,\n",
        "    'kernel_size': 3,\n",
        "    'padding': 'same',\n",
        "    'dropout': 0.1,\n",
        "    'pool_stride': 2,\n",
        "    'feature_labels': [12, 12], # Adjust element 1 based on number of valid labels for task.\n",
        "    'in_channels': [64, 64, 128, 256],\n",
        "    'out_channels': [64, 128, 256, 512],\n",
        "    'mlp_dims': [512, 1024, 1024, 512]\n",
        "}"
      ],
      "metadata": {
        "id": "_3mW8yG5N_eL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torchinfo.summary(Light_UNet(**model_config), input_size=((1, 12, 120, 120)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3suHBSihYTaW",
        "outputId": "b5eebf77-9cd1-48d5-c768-a23e94aa5227"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Light_UNet                               [1, 20, 120, 120]         --\n",
              "├─Sequential: 1-1                        [1, 64, 120, 120]         --\n",
              "│    └─Conv2d: 2-1                       [1, 64, 120, 120]         6,912\n",
              "│    └─BatchNorm2d: 2-2                  [1, 64, 120, 120]         128\n",
              "│    └─ReLU: 2-3                         [1, 64, 120, 120]         --\n",
              "├─Encoder: 1-2                           [1, 64, 120, 120]         --\n",
              "│    └─FeatureConvs: 2-4                 [1, 64, 120, 120]         --\n",
              "│    │    └─Sequential: 3-1              [1, 64, 120, 120]         73,984\n",
              "├─Encoder: 1-3                           [1, 128, 60, 60]          --\n",
              "│    └─FeatureConvs: 2-5                 [1, 128, 60, 60]          --\n",
              "│    │    └─Sequential: 3-2              [1, 128, 60, 60]          110,976\n",
              "├─Encoder: 1-4                           [1, 256, 30, 30]          --\n",
              "│    └─FeatureConvs: 2-6                 [1, 256, 30, 30]          --\n",
              "│    │    └─Sequential: 3-3              [1, 256, 30, 30]          443,136\n",
              "├─Encoder: 1-5                           [1, 512, 15, 15]          --\n",
              "│    └─FeatureConvs: 2-7                 [1, 512, 15, 15]          --\n",
              "│    │    └─Sequential: 3-4              [1, 512, 15, 15]          1,771,008\n",
              "├─Bottleneck: 1-6                        [1, 256, 15, 15]          --\n",
              "│    └─ModuleList: 2-8                   --                        --\n",
              "│    │    └─MLPBlock: 3-5                [1, 15, 15, 1024]         526,336\n",
              "│    │    └─MLPBlock: 3-6                [1, 15, 15, 1024]         1,050,624\n",
              "│    │    └─MLPBlock: 3-7                [1, 15, 15, 512]          525,312\n",
              "│    └─Sequential: 2-9                   [1, 256, 15, 15]          --\n",
              "│    │    └─Conv2d: 3-8                  [1, 256, 15, 15]          1,179,648\n",
              "│    │    └─BatchNorm2d: 3-9             [1, 256, 15, 15]          512\n",
              "│    │    └─ReLU: 3-10                   [1, 256, 15, 15]          --\n",
              "├─Decoder: 1-7                           [1, 128, 30, 30]          --\n",
              "│    └─Conv2d: 2-10                      [1, 256, 30, 30]          65,792\n",
              "│    └─FeatureConvs: 2-11                [1, 128, 30, 30]          --\n",
              "│    │    └─Sequential: 3-11             [1, 128, 30, 30]          885,504\n",
              "├─Decoder: 1-8                           [1, 64, 60, 60]           --\n",
              "│    └─Conv2d: 2-12                      [1, 128, 60, 60]          16,512\n",
              "│    └─FeatureConvs: 2-13                [1, 64, 60, 60]           --\n",
              "│    │    └─Sequential: 3-12             [1, 64, 60, 60]           221,568\n",
              "├─Decoder: 1-9                           [1, 64, 120, 120]         --\n",
              "│    └─Conv2d: 2-14                      [1, 64, 120, 120]         4,160\n",
              "│    └─FeatureConvs: 2-15                [1, 64, 120, 120]         --\n",
              "│    │    └─Sequential: 3-13             [1, 64, 120, 120]         73,984\n",
              "├─Conv2d: 1-10                           [1, 20, 120, 120]         1,300\n",
              "==========================================================================================\n",
              "Total params: 6,957,396\n",
              "Trainable params: 6,957,396\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (Units.GIGABYTES): 5.47\n",
              "==========================================================================================\n",
              "Input size (MB): 0.69\n",
              "Forward/backward pass size (MB): 135.01\n",
              "Params size (MB): 27.83\n",
              "Estimated Total Size (MB): 163.54\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration:"
      ],
      "metadata": {
        "id": "SeUSwGfL-3GT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate configuration and model variables.\n",
        "\n",
        "config_vars = {\n",
        "    'seed': 123,\n",
        "    'drive_path': 'MyDrive/Semantic Segmentation/data/new_natural_ecosystems',\n",
        "    'save_path': 'MyDrive/Semantic Segmentation/light u-net chpts', # Google Drive directory to save the file.\n",
        "    'train_bs': 128,\n",
        "    'val_bs': 256,\n",
        "    'test_bs': 512,\n",
        "    'device': 'cuda',\n",
        "    'loss_fn': torch.nn.CrossEntropyLoss(ignore_index=0),\n",
        "    'epochs': 100,\n",
        "    'model': Light_UNet(**model_config), # Add the initialized model.\n",
        "    'optimizer': torch.optim.AdamW,\n",
        "    'optimizer_params': {'lr': 1e-3, 'weight_decay': 1e-2},\n",
        "    'scheduler_params': {\n",
        "        'schedulers': [\n",
        "            (lr_scheduler.LinearLR, {'start_factor': 5e-5/1e-3, 'total_iters': 5}),\n",
        "            (lr_scheduler.CosineAnnealingLR, {'T_max': 95})\n",
        "        ],\n",
        "        'milestones': [5]\n",
        "    },\n",
        "    'patience': 10\n",
        "}"
      ],
      "metadata": {
        "id": "jT-qfut--2c6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset:"
      ],
      "metadata": {
        "id": "3WXNdOkz-rTk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "aKBkRYA4-qdo"
      },
      "outputs": [],
      "source": [
        "def create_dataset(**kwargs):\n",
        "  drive_path = kwargs.get('drive_path') # Path to dataset folder.\n",
        "\n",
        "  # Natural land cover.\n",
        "  unique_classes = [0, 311, 312, 313, 321, 322, 324, 333, 411, 412, 511, 512]\n",
        "  mapping = {v: i for i, v in enumerate(unique_classes)}\n",
        "  max_class_value = max(unique_classes)\n",
        "  lookup = np.full(max_class_value + 1, -1, dtype=int)\n",
        "  for k, v in mapping.items():\n",
        "      lookup[k] = v\n",
        "\n",
        "  mean_stds = [[], []]\n",
        "\n",
        "  class DatasetGenerator(utils.Dataset):\n",
        "    def __init__(self, split):\n",
        "\n",
        "      self.split = split\n",
        "\n",
        "      shutil.copyfile(f'/content/drive/{drive_path}/{split}.npy', f'/content/{split}.npy')\n",
        "      self.data = np.load(f'/content/{split}.npy')\n",
        "\n",
        "      # Compute global normalization values.\n",
        "      if split == 'train':\n",
        "        for id_ch in range(12):\n",
        "          ch_data = self.data[:, id_ch, :, :]\n",
        "          mean_stds[0].append(np.mean(ch_data)/10000)\n",
        "          mean_stds[1].append(np.std(ch_data)/10000)\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      data = self.data[idx]\n",
        "\n",
        "      if self.split == 'train':\n",
        "        data = self.augment_data(data)\n",
        "\n",
        "      features = data[:-1, :, :].astype(np.float32) / 10000 # Correctly scale the data according to the raw reflectance values.\n",
        "      labels = data[-1, :, :].astype(np.uint16)\n",
        "\n",
        "      for id_ch in range(12):\n",
        "        features[id_ch, :, :] = (features[id_ch, :, :] - mean_stds[0][id_ch]) / mean_stds[1][id_ch]\n",
        "\n",
        "      labels[np.isin(labels, [111, 112, 121, 122, 123, 124, 131, 132, 133, 141, 142, 211, 212, 213, 221, 222, 223, 231, 241, 242, 243, 244, 323, 331, 332, 334, 421, 422, 423, 521, 522, 523, 999])] = 0\n",
        "      labels = lookup[labels]\n",
        "\n",
        "      return features, labels\n",
        "\n",
        "    def augment_data(self, x):\n",
        "      transforms_list = []\n",
        "\n",
        "      if np.random.random() <= 0.5:\n",
        "        transforms_list.append(v2.RandomHorizontalFlip(p=1.0))\n",
        "\n",
        "      if np.random.random() <= 0.5:\n",
        "        transforms_list.append(v2.RandomVerticalFlip(p=1.0))\n",
        "\n",
        "      if np.random.random() <= 0.25:\n",
        "        transforms_list.append(v2.RandomRotation(degrees=135))\n",
        "\n",
        "      # if np.random.random() <= 0.15:\n",
        "      #   transforms_list.append(v2.GaussianNoise(sigma=50, clip=True)) # Reduce simga to 0.05 first if underfitting, or try different sigmas based on band mean (ie. B01-02 has lower values for some samples).\n",
        "\n",
        "      if transforms_list:\n",
        "        return v2.Compose(transforms_list)(x)\n",
        "      return x\n",
        "\n",
        "\n",
        "  train_set = DatasetGenerator('train')\n",
        "  print('Train Copied')\n",
        "  validation_set = DatasetGenerator('validation')\n",
        "  print('Validation Copied')\n",
        "  test_set = DatasetGenerator('test')\n",
        "  print('Test Copied')\n",
        "\n",
        "  return (utils.DataLoader(train_set, batch_size=kwargs.get('train_bs'), shuffle=True, drop_last=True, num_workers=8, persistent_workers=True, pin_memory=True),\n",
        "          utils.DataLoader(validation_set, batch_size=kwargs.get('val_bs'), shuffle=False, drop_last=True, num_workers=8, persistent_workers=True, pin_memory=True),\n",
        "          utils.DataLoader(test_set, batch_size=kwargs.get('test_bs'), shuffle=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training:"
      ],
      "metadata": {
        "id": "Xo8g04t4-xaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "  def __init__(self, patience, tol=0.01):\n",
        "    self.patience = patience\n",
        "    self.tol = tol\n",
        "\n",
        "    self.cur_epoch = 0\n",
        "    self.lowest_val_loss = float(0)\n",
        "    self.best_model = None\n",
        "\n",
        "\n",
        "  def __call__(self, val_loss, model):\n",
        "    if (val_loss <= self.lowest_val_loss-self.tol or self.lowest_val_loss == 0):\n",
        "      self.cur_epoch = 0\n",
        "      self.best_model = model.state_dict()\n",
        "      self.lowest_val_loss = val_loss\n",
        "    else:\n",
        "      self.cur_epoch += 1 # Increment counter if no improvement\n",
        "\n",
        "    if self.cur_epoch == self.patience:\n",
        "      return self.best_model\n",
        "\n",
        "    return None"
      ],
      "metadata": {
        "id": "EkpJ1hEVxb4y"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(train_loader, val_loader, **kwargs):\n",
        "  device = kwargs.get('device')\n",
        "  patience = kwargs.get('patience')\n",
        "  save_path = kwargs.get('save_path')\n",
        "\n",
        "\n",
        "  model = kwargs.get('model').to(device)\n",
        "  model.init_weights()\n",
        "\n",
        "\n",
        "  optimizer = kwargs.get('optimizer')(model.parameters(), **kwargs.get('optimizer_params'))\n",
        "  scheduler = None\n",
        "  if kwargs.get('scheduler_params'):\n",
        "    scheduler_details = kwargs.get('scheduler_params')\n",
        "    schedulers_list = [scheduler_class(optimizer, **params) for scheduler_class, params in scheduler_details.get('schedulers')]\n",
        "    scheduler = lr_scheduler.SequentialLR(optimizer, schedulers=schedulers_list, milestones=scheduler_details.get('milestones'))\n",
        "\n",
        "  loss_fn = kwargs.get('loss_fn')\n",
        "\n",
        "  if patience:\n",
        "    early_stop = EarlyStopping(patience=patience)\n",
        "\n",
        "  for epoch in range(1, kwargs.get('epochs')+1):\n",
        "    train_loss = float(0)\n",
        "\n",
        "    model.train(mode=True)\n",
        "    for data in train_loader:\n",
        "      input_data, label = data\n",
        "      input_data = input_data.to(device)\n",
        "      label = label.to(device)\n",
        "\n",
        "      # for ch in range(12):\n",
        "      #   print(ch, input_data[0, ch, ...].mean())\n",
        "\n",
        "      # print(label[0, ...].unique())\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      with torch.autocast(device, dtype=torch.bfloat16):\n",
        "        pred_label = model(input_data)\n",
        "        loss = loss_fn(pred_label, label)\n",
        "\n",
        "      train_loss += loss.detach().item()\n",
        "\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "    if (epoch - 1) % 5 == 0:\n",
        "      torch.save(model.state_dict(), f'/content/drive/{save_path}/epoch_{epoch}.pth')\n",
        "\n",
        "\n",
        "    model.train(mode=False)\n",
        "    with torch.no_grad():\n",
        "      val_loss = float(0)\n",
        "\n",
        "      for data in val_loader:\n",
        "        input_data, label = data\n",
        "        input_data_val = input_data.to(device)\n",
        "        label_val = label.to(device)\n",
        "\n",
        "        pred_label_val = model(input_data_val)\n",
        "        loss = loss_fn(pred_label_val, label_val)\n",
        "\n",
        "        val_loss += loss.detach().item()\n",
        "\n",
        "      train_loss /= len(train_loader)\n",
        "      val_loss /= len(val_loader)\n",
        "\n",
        "      if patience and early_stop:\n",
        "        es_result = early_stop(val_loss, model)\n",
        "        if es_result:\n",
        "          torch.save(es_result, f'/content/drive/{save_path}/BEST_epoch_{epoch-patience}.pth')\n",
        "          break\n",
        "\n",
        "    if scheduler:\n",
        "      scheduler.step()\n",
        "\n",
        "    print(f'Epoch {epoch}:\\n Train Loss: {train_loss}\\n Val Loss: {val_loss}')"
      ],
      "metadata": {
        "id": "Hifs61J--7SK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main:"
      ],
      "metadata": {
        "id": "2OneDd0TqqqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(config_vars.get('drive_path'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDBGhi0oIhfb",
        "outputId": "113c2824-54ff-4fb9-c113-d36d7fa112fa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MyDrive/Semantic Segmentation/data/new_natural_ecosystems\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def training_pipeline(**kwargs):\n",
        "  # Set seeds for reproducibility.\n",
        "  seed = kwargs.get('seed')\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  torch.use_deterministic_algorithms(True)\n",
        "\n",
        "\n",
        "  train_data, val_data, test_data = create_dataset(**kwargs)\n",
        "  train_model(train_data, val_data, **kwargs)"
      ],
      "metadata": {
        "id": "qA-3VQLMsoWV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  training_pipeline(**config_vars)"
      ],
      "metadata": {
        "id": "ayyO_Tkgqs6z",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}